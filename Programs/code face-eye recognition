import cv2
import numpy
prev = []
zoomed = []
face_cascade = cv2.CascadeClassifier(r'./xml/haarcascade_frontalface_default.xml')
#eye_cascade = cv2.CascadeClassifier(r'./xml/haarcascade_eye.xml')

cap = cv2.VideoCapture(0)
start = None

while True:
    ret, img = cap.read()
    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray_img, 1.25, 4)

    """
    for (x, y, w, h) in faces:
        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 255, 0), 2)
        rec_gray = gray_img[y:y + h, x:x + w]
        rec_color = img[y:y + h, x:x + w]

        zoomed = img[y:y + h, x:x + w]
        start = True
        #eyes = eye_cascade.detectMultiScale(rec_gray)

        #for (a, b, c, d) in eyes:
        #    cv2.rectangle(rec_color, (a, b), (a+c, b+d), (0, 127, 255), 2)
        
    print('faces:', faces)
    if prev is not None:
        for i in range(0, len(faces)):
            q = prev[i] == faces[i]
            print('q:', q)
            if not all(q):
                prev[i] = faces[i]
            elif i > len(prev):
                prev.append(faces[i])
            else:
                numpy.delete(prev, i)
                print('prev:', prev)
    else:
        prev = faces
    """

    print('faces:', faces, len(faces))
    print('len(zoomed):', len(zoomed))
    for i in range(len(faces)):
        print('faces[i]:', faces[i])
        if len(faces) > len(zoomed):
            zoomed.append([])
        (x, y, w, h) = faces[i]
        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 255, 0), 2)
        rec_gray = gray_img[y:y + h, x:x + w]
        rec_color = img[y:y + h, x:x + w]
        h2 = 75
        w2 = 75
        if y < h2:
            h2 = y
        if x + w2 + w > len(gray_img[0]):
            w2 = len(gray_img[0]) - w - x
        if x < w2:
            w2 = x
        if y + h + h2 > len(gray_img):
            h2 = len(gray_img) - y - h
        zoomed[i] = img[y-h2:y + h + h2, x - w2:x + w + w2]
        print('zoomed[i]:', zoomed[i])
        """
        if len(zoomed) > len(faces):
            verschil = len(zoomed) - len(faces)
            zoomed = zoomed[:-verschil]
            for j in range(len(faces), len(zoomed)):
                print(len(faces)+j+1)
                cv2.destroyWindow('Zoom in ' + str(len(faces)+j+1))
        """
        #print(len(gray_img))
        #print(len(gray_img[0]))
        cv2.imshow('Zoom in ' + str(i + 1), zoomed[i])
        cv2.resizeWindow('Zoom in ' + str(i+1), 300, 300)
        """
        if 'hoofd'+str(i+1) in prev:
            print(prev['hoofd'+str(i+1)])
            if prev['hoofd'+str(i+1)] == [x,y]:
                print('hoofd' + str(i+1))
                faces.pop('hoofd' + str(i+1),None)
        prev['hoofd'+str(i+1)] = [x, y]
        """

    #print('prev:',prev)
    if len(faces) != len(prev) and len(prev) != 0:
        cv2.destroyWindow('Zoom in ' + str(len(zoomed)))

    cv2.imshow('Face Recognition', img)
    #if start and zoomed.all() is not None:
    #    cv2.imshow('Zoom in', zoomed)
    prev = faces

    k = cv2.waitKey(30) & 0xff
    if k == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
